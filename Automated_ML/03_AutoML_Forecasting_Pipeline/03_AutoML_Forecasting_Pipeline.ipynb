{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 予測パイプライン - 自動化 ML\r\n",
    "\r\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/automated-machine-learning/manymodels/03_Forecasting/03_Forecasting_Pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このノートブックでは、11,973 の AutoML モデルのバッチ予測を行うためのパイプラインを作成します。これらのモデルのトレーニングとスコアリングは、このリポジトリのトレーニング ノートブックで完了しました。ここでは目的の予測期間を基に、予測用のパイプラインを設定します。プロセスを並列化するために、AutoMLPipelineBuilder を活用します。データとモデルの詳細については、データ準備およびトレーニングノートブックを参照してください。\r\n",
    "\r\n",
    "パイプラインの設定は、このリポジトリのトレーニング パイプラインと似ています。手順と機能の詳細については、トレーニングフォルダを参照してください。\r\n",
    "\r\n",
    "### 前提条件\r\n",
    "この時点で、次の内容が完了している必要があります:\r\n",
    "\r\n",
    "1. [00_Setup_AML_Workspace notebook](../../00_Setup_AML_Workspace.ipynb) を使用して AML ワークスペースが作成作成済みであること\r\n",
    "2. [01_Data_Preparation.ipynb](../../01_Data_Preparation.ipynb) を実行してデータセットが作成済みであること\r\n",
    "3. [02_AutoML_Training_Pipeline.ipynb](../02_AutoML_Training_Pipeline/02_AutoML_Training_Pipeline.ipynb) を実行してモデルがトレーニング済みであること"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "azureml.contrib.automl.pipeline.steps パッケージをインストールします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install azureml-contrib-automl-pipeline-steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 ワークスペース、データストア、およびコンピューティングの呼び出し\r\n",
    "\r\n",
    "トレーニング パイプライン ノートブックで行ったように、ワークスペースを呼び出す必要があります。また、データストアとコンピューティングクラスターの変数を作成します。\r\n",
    "\r\n",
    "### ワークスペースに接続する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\r\n",
    "from azureml.core import Workspace, Datastore\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "# ワークスペースのセットアップ\r\n",
    "ws= Workspace.from_config() \r\n",
    "\r\n",
    "# ワークスペースの確認\r\n",
    "ws.get_details()\r\n",
    "\r\n",
    "# データストアのセットアップ\r\n",
    "dstore = ws.get_default_datastore()\r\n",
    "\r\n",
    "output = {}\r\n",
    "output['SDK version'] = azureml.core.VERSION\r\n",
    "output['Subscription ID'] = ws.subscription_id\r\n",
    "output['Workspace'] = ws.name\r\n",
    "output['Resource Group'] = ws.resource_group\r\n",
    "output['Location'] = ws.location\r\n",
    "output['Default datastore name'] = dstore.name\r\n",
    "pd.set_option('display.max_colwidth', -1)\r\n",
    "outputDf = pd.DataFrame(data = output, index = [''])\r\n",
    "outputDf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 既存のコンピュート リソースをアタッチする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\r\n",
    "\r\n",
    "# クラスタの名前を選択\r\n",
    "amlcompute_cluster_name = \"cpucluster\"\r\n",
    "\r\n",
    "found = False\r\n",
    "# ワークスペースにこのコンピュート ターゲットが存在しているか確認\r\n",
    "cts = ws.compute_targets\r\n",
    "if amlcompute_cluster_name in cts and cts[amlcompute_cluster_name].type == 'AmlCompute':\r\n",
    "    found = True\r\n",
    "    print('既存のコンピュート ターゲットがあります。')\r\n",
    "    compute = cts[amlcompute_cluster_name]\r\n",
    "    \r\n",
    "if not found:\r\n",
    "    print('新しいコンピュート ターゲットを作成しています...')\r\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D16S_V3',\r\n",
    "                                                           min_nodes=2,\r\n",
    "                                                           max_nodes=20)\r\n",
    "    # クラスタの作成\r\n",
    "    compute = ComputeTarget.create(ws, amlcompute_cluster_name, provisioning_config)\r\n",
    "    \r\n",
    "print('クラスタの状態を確認中...')\r\n",
    "# 最小ノード数と特定のタイムアウトをポーリングできます。\r\n",
    "# min_node_count が提供されていない場合は、クラスターのスケール設定が使用されます。\r\n",
    "compute.wait_for_completion(show_output = True, min_node_count = None, timeout_in_minutes = 20)\r\n",
    "    \r\n",
    "# 現在の AmlCompute ステータスの詳細なビューは、get_status() を使用して確認できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実験のセットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment = Experiment(ws, 'manymodels-forecasting-pipeline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 登録済みの FileDataset を呼び出す\r\n",
    "データ準備ノートブックでは、オレンジジュースの推論データをワークスペースに登録しました。10 シリーズのサブレットまたは 11,973 シリーズの完全なデータセットでパイプラインを実行することを選択できます。10シリーズから始めて拡大することをお勧めします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "filedst_10_models = Dataset.get_by_name(ws, name='oj_data_small_inference')\n",
    "filedst_10_models_input = filedst_10_models.as_named_input('forecast_10_models')\n",
    " \n",
    "#filedst_all_models = Dataset.get_by_name(ws, name='oj_data_inference')\n",
    "#filedst_all_models_input = filedst_all_models.as_named_input('forecast_all_models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 予測パイプラインの構築\r\n",
    "Now that the data, models, and compute resources are set up, we can put together a pipeline for forecasting. \r\n",
    "### Set up the environment to run the script\r\n",
    "Specify the conda dependencies for your script. This will allow us to install packages and configure the environment.\r\n",
    "\r\n",
    "\r\n",
    "データ、モデル、およびコンピューティング リソースを設定したので、予測用のパイプラインをまとめることができます。\r\n",
    "\r\n",
    "スクリプトを実行するための環境のセットアップ\r\n",
    "スクリプトの conda 依存関係を指定します。これにより、パッケージをインストールして環境を構成できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_experiment_name = \"<training_experiment_name_goes_here>\"\n",
    "training_pipeline_run_id =\"<training_pipeline_run_id_goes_here>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the configuration to wrap the entry script \n",
    "AutoMLPipelineBuilder is used to build the inference step for many models. You will need to determine the number of workers and nodes appropriate for your use case. The process_count_per_node is based off the number of cores of the compute VM. The node_count will determine the number of master nodes to use, increasing the node count will speed up the training process.\n",
    "\n",
    "* <b>experiment</b>: Current experiment.\n",
    "\n",
    "* <b>inference_data</b>: Inference dataset.\n",
    "\n",
    "* <b>compute_target</b>: Compute target for inference.\n",
    "\n",
    "* <b>node_count</b>: The number of compute nodes to be used for running the user script. We recommend to start with 3 and increase the node_count if the training time is taking too long.\n",
    "\n",
    "* <b>process_count_per_node</b>: The number of processes per node.\n",
    "\n",
    "* <b>run_invocation_timeout</b>: The run() method invocation timeout in seconds. The timeout should be set to maximum training time of one AutoML run(with some buffer), by default it's 60 seconds.\n",
    "\n",
    "* <b>output_datastore</b>: Output datastore to output the inference results.\n",
    "\n",
    "* <b>train_experiment_name</b>: Training experiment name where many models were trained.\n",
    "\n",
    "* <b>train_run_id</b>: Training run id where many models were trained.\n",
    "\n",
    "* <b>partition_column_names</b>: Partition column names.\n",
    "\n",
    "* <b>time_column_name(Optional)</b>: Time column name if it is timeseries\n",
    "\n",
    "* <b>target_column_name(Optional)</b>: Target column name if the inference dataset has the target column\n",
    "\n",
    "<span style=\"color:red\"><b>NOTE: There are limits on how many runs we can do in parallel per workspace, and we currently recommend to set the parallelism to maximum of 320 runs per experiment per workspace. If users want to have more parallelism and increase this limit they might encounter Too Many Requests errors (HTTP 429). </b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.contrib.automl.pipeline.steps import AutoMLPipelineBuilder\n",
    "\n",
    "partition_column_names = ['Store', 'Brand']\n",
    "\n",
    "inference_steps = AutoMLPipelineBuilder.get_many_models_batch_inference_steps(experiment=experiment,\n",
    "                                                                              inference_data=filedst_10_models_input,\n",
    "                                                                              compute_target=compute,\n",
    "                                                                              node_count=2,\n",
    "                                                                              process_count_per_node=8,\n",
    "                                                                              run_invocation_timeout=300,\n",
    "                                                                              output_datastore=dstore,\n",
    "                                                                              train_experiment_name=training_experiment_name,\n",
    "                                                                              train_run_id=training_pipeline_run_id,\n",
    "                                                                              partition_column_names=partition_column_names,\n",
    "                                                                              time_column_name=\"WeekStarting\",\n",
    "                                                                              target_column_name=\"Quantity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Run the forecast pipeline\n",
    "We can use the Experiment we created to track the runs of the pipeline and review the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "pipeline = Pipeline(workspace = ws, steps=inference_steps)\n",
    "run = experiment.submit(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the folowing command if you'd like to monitor the forecasting process in jupyter notebook. It will stream logs live while forecasting. \n",
    "\n",
    "**Note**: this command may not work for Notebook VM, however it should work on your local laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Succesfully forecasted on AutoML Models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Pipeline Outputs\n",
    "The forecasting pipeline forecasts the orange juice quantity for a Store by Brand. The pipeline returns one file with the predictions for each store and outputs the result to the forecasting_output Blob container. The details of the blob container is listed in 'forecasting_output.txt' under Outputs+logs. \n",
    "\n",
    "The following code snippet:\n",
    "1. Downloads the contents of the output folder that is passed in the parallel run step \n",
    "2. Reads the parallel_run_step.txt file that has the predictions as pandas dataframe and \n",
    "3. Displays the top 10 rows of the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "import sys \n",
    "from scripts.helper import get_forecasting_output\n",
    "\n",
    "forecasting_results_name = \"forecasting_results\"\n",
    "forecasting_output_name = \"many_models_inference_output\"\n",
    "\n",
    "forecast_file = get_forecasting_output(run, forecasting_results_name, forecasting_output_name)\n",
    "df = pd.read_csv(forecast_file, delimiter=\" \", header=None)\n",
    "df.columns = [\"Week Starting\", \"Store\", \"Brand\", \"Quantity\",  \"Advert\", \"Price\" , \"Revenue\", \"Predicted\" ]\n",
    "print(\"Prediction has \", df.shape[0], \" rows. Here the first 10 rows are being displayed.\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0 Publish and schedule the pipeline (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Publish the pipeline\n",
    "\n",
    "Once you have a pipeline you're happy with, you can publish a pipeline so you can call it programmatically later on. See this [tutorial](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-create-your-first-pipeline#publish-a-pipeline) for additional information on publishing and calling pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# published_pipeline = pipeline.publish(name = 'automl_forecast_many_models',\n",
    "#                                      description = 'forecast many models',\n",
    "#                                      version = '1',\n",
    "#                                      continue_on_step_failure = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Schedule the pipeline\n",
    "You can also [schedule the pipeline](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-schedule-pipelines) to run on a time-based or change-based schedule. This could be used to automatically retrain or forecast models every month or based on another trigger such as data drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azureml.pipeline.core import Schedule, ScheduleRecurrence\n",
    "    \n",
    "# forecasting_pipeline_id = published_pipeline.id\n",
    "\n",
    "# recurrence = ScheduleRecurrence(frequency=\"Month\", interval=1, start_time=\"2020-01-01T09:00:00\")\n",
    "# recurring_schedule = Schedule.create(ws, name=\"automl_forecasting_recurring_schedule\", \n",
    "#                             description=\"Schedule Forecasting Pipeline to run on the first day of every week\",\n",
    "#                             pipeline_id=forecasting_pipeline_id, \n",
    "#                             experiment_name=experiment.name, \n",
    "#                             recurrence=recurrence)"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "deeptim"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}