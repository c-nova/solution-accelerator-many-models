{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 予測パイプライン - 自動化 ML\r\n",
    "\r\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/automated-machine-learning/manymodels/03_Forecasting/03_Forecasting_Pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このノートブックでは、11,973 の AutoML モデルのバッチ予測を行うためのパイプラインを作成します。これらのモデルのトレーニングとスコアリングは、このリポジトリのトレーニング ノートブックで完了しました。ここでは目的の予測期間を基に、予測用のパイプラインを設定します。プロセスを並列化するために、AutoMLPipelineBuilder を活用します。データとモデルの詳細については、データ準備およびトレーニングノートブックを参照してください。\r\n",
    "\r\n",
    "パイプラインの設定は、このリポジトリのトレーニング パイプラインと似ています。手順と機能の詳細については、トレーニングフォルダを参照してください。\r\n",
    "\r\n",
    "### 前提条件\r\n",
    "この時点で、次の内容が完了している必要があります:\r\n",
    "\r\n",
    "1. [00_Setup_AML_Workspace notebook](../../00_Setup_AML_Workspace.ipynb) を使用して AML ワークスペースが作成作成済みであること\r\n",
    "2. [01_Data_Preparation.ipynb](../../01_Data_Preparation.ipynb) を実行してデータセットが作成済みであること\r\n",
    "3. [02_AutoML_Training_Pipeline.ipynb](../02_AutoML_Training_Pipeline/02_AutoML_Training_Pipeline.ipynb) を実行してモデルがトレーニング済みであること"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "azureml.contrib.automl.pipeline.steps パッケージをインストールします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install azureml-contrib-automl-pipeline-steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 ワークスペース、データストア、およびコンピューティングの呼び出し\r\n",
    "\r\n",
    "トレーニング パイプライン ノートブックで行ったように、ワークスペースを呼び出す必要があります。また、データストアとコンピューティングクラスターの変数を作成します。\r\n",
    "\r\n",
    "### ワークスペースに接続する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\r\n",
    "from azureml.core import Workspace, Datastore\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "# ワークスペースのセットアップ\r\n",
    "ws= Workspace.from_config() \r\n",
    "\r\n",
    "# ワークスペースの確認\r\n",
    "ws.get_details()\r\n",
    "\r\n",
    "# データストアのセットアップ\r\n",
    "dstore = ws.get_default_datastore()\r\n",
    "\r\n",
    "output = {}\r\n",
    "output['SDK version'] = azureml.core.VERSION\r\n",
    "output['Subscription ID'] = ws.subscription_id\r\n",
    "output['Workspace'] = ws.name\r\n",
    "output['Resource Group'] = ws.resource_group\r\n",
    "output['Location'] = ws.location\r\n",
    "output['Default datastore name'] = dstore.name\r\n",
    "pd.set_option('display.max_colwidth', -1)\r\n",
    "outputDf = pd.DataFrame(data = output, index = [''])\r\n",
    "outputDf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 既存のコンピュート リソースをアタッチする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\r\n",
    "\r\n",
    "# クラスタの名前を選択\r\n",
    "amlcompute_cluster_name = \"cpucluster\"\r\n",
    "\r\n",
    "found = False\r\n",
    "# ワークスペースにこのコンピュート ターゲットが存在しているか確認\r\n",
    "cts = ws.compute_targets\r\n",
    "if amlcompute_cluster_name in cts and cts[amlcompute_cluster_name].type == 'AmlCompute':\r\n",
    "    found = True\r\n",
    "    print('既存のコンピュート ターゲットがあります。')\r\n",
    "    compute = cts[amlcompute_cluster_name]\r\n",
    "    \r\n",
    "if not found:\r\n",
    "    print('新しいコンピュート ターゲットを作成しています...')\r\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D16S_V3',\r\n",
    "                                                           min_nodes=2,\r\n",
    "                                                           max_nodes=20)\r\n",
    "    # クラスタの作成\r\n",
    "    compute = ComputeTarget.create(ws, amlcompute_cluster_name, provisioning_config)\r\n",
    "    \r\n",
    "print('クラスタの状態を確認中...')\r\n",
    "# 最小ノード数と特定のタイムアウトをポーリングできます。\r\n",
    "# min_node_count が提供されていない場合は、クラスターのスケール設定が使用されます。\r\n",
    "compute.wait_for_completion(show_output = True, min_node_count = None, timeout_in_minutes = 20)\r\n",
    "    \r\n",
    "# 現在の AmlCompute ステータスの詳細なビューは、get_status() を使用して確認できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実験のセットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment = Experiment(ws, 'manymodels-forecasting-pipeline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 登録済みの FileDataset を呼び出す\r\n",
    "データ準備ノートブックでは、オレンジジュースの推論データをワークスペースに登録しました。10 シリーズのサブレットまたは 11,973 シリーズの完全なデータセットでパイプラインを実行することを選択できます。10シリーズから始めて拡大することをお勧めします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "filedst_10_models = Dataset.get_by_name(ws, name='oj_data_small_inference')\n",
    "filedst_10_models_input = filedst_10_models.as_named_input('forecast_10_models')\n",
    " \n",
    "#filedst_all_models = Dataset.get_by_name(ws, name='oj_data_inference')\n",
    "#filedst_all_models_input = filedst_all_models.as_named_input('forecast_all_models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 予測パイプラインの構築\r\n",
    "Now that the data, models, and compute resources are set up, we can put together a pipeline for forecasting. \r\n",
    "### Set up the environment to run the script\r\n",
    "Specify the conda dependencies for your script. This will allow us to install packages and configure the environment.\r\n",
    "\r\n",
    "\r\n",
    "データ、モデル、およびコンピューティング リソースを設定したので、予測用のパイプラインをまとめることができます。\r\n",
    "\r\n",
    "スクリプトを実行するための環境のセットアップ\r\n",
    "スクリプトの conda 依存関係を指定します。これにより、パッケージをインストールして環境を構成できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_experiment_name = \"<training_experiment_name_goes_here>\"\n",
    "training_pipeline_run_id =\"<training_pipeline_run_id_goes_here>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### エントリスクリプトをラップする構成を作成する\r\n",
    "AutoMLPipelineBuilder は、多くのモデルの推論ステップを構築するために使用されます。ユースケースに適したワーカーとノードの数を決定する必要があります。 process_count_per_node は、コンピューティングVMのコア数に基づいています。 node_count は、使用するマスターノードの数を決定します。ノード数を増やすと、トレーニングプロセスが高速化されます。\r\n",
    "\r\n",
    "* <b>experiment</b>: 現在の実験。\r\n",
    "\r\n",
    "* <b>inference_data</b>: 推論データセット。\r\n",
    "\r\n",
    "* <b>compute_target</b>: 推論用のコンピュートターゲット。\r\n",
    "\r\n",
    "* <b>node_count</b>: ユーザー スクリプトの実行に使用するコンピューティング ノードの数。3から始めることをお勧めしますが、トレーニング時間が長すぎる場合には node_countを増やします。\r\n",
    "\r\n",
    "* <b>process_count_per_node</b>: ノードあたりのプロセス数。\r\n",
    "\r\n",
    "* <b>run_invocation_timeout</b>: run() メソッドの呼び出しタイムアウト (秒単位)。タイムアウトは、AutoML の実行の最大トレーニング時間 (及び多少のバッファ) 内に設定する必要があります。デフォルトは 60 秒です。\r\n",
    "\r\n",
    "* <b>output_datastore</b>: 推論結果を出力する出力用データストアを指定します。\r\n",
    "\r\n",
    "* <b>train_experiment_name</b>: Many Models がトレーニングされたトレーニング実験名。\r\n",
    "\r\n",
    "* <b>train_run_id</b>: Many Models がトレーニングされたトレーニング実行ID。\r\n",
    "\r\n",
    "* <b>partition_column_names</b>: パーティション列名。\r\n",
    "\r\n",
    "* <b>time_column_name(オプション)</b>: 時系列の場合は時間列名\r\n",
    "\r\n",
    "* <b>target_column_name(オプション)</b>: 推論データセットにターゲット列がある場合にはターゲット列名\r\n",
    "\r\n",
    "<span style=\"color:red\"><b>注: ワークスペースごとに並列実行できる実行の数には制限があり、現在は、ワークスペースごとに並列処理を 1 つの実験あたり最大 320 回に設定することをお勧めします。ユーザーがより多くの並列処理を必要とし、この制限を増やす場合、要求数過多エラー (HTTP 429) が発生する可能性があります。</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.contrib.automl.pipeline.steps import AutoMLPipelineBuilder\n",
    "\n",
    "partition_column_names = ['Store', 'Brand']\n",
    "\n",
    "inference_steps = AutoMLPipelineBuilder.get_many_models_batch_inference_steps(experiment=experiment,\n",
    "                                                                              inference_data=filedst_10_models_input,\n",
    "                                                                              compute_target=compute,\n",
    "                                                                              node_count=2,\n",
    "                                                                              process_count_per_node=8,\n",
    "                                                                              run_invocation_timeout=300,\n",
    "                                                                              output_datastore=dstore,\n",
    "                                                                              train_experiment_name=training_experiment_name,\n",
    "                                                                              train_run_id=training_pipeline_run_id,\n",
    "                                                                              partition_column_names=partition_column_names,\n",
    "                                                                              time_column_name=\"WeekStarting\",\n",
    "                                                                              target_column_name=\"Quantity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 予測パイプラインを実行する\r\n",
    "作成した実験を使用して、パイプラインの実行を追跡し、出力を確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "pipeline = Pipeline(workspace = ws, steps=inference_steps)\n",
    "run = experiment.submit(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jupyter ノートブックで予測プロセスを監視する場合は、以下のコマンドを実行します。予測中にログをライブストリーミングします。\r\n",
    "\r\n",
    "**注**: このコマンドはコンピューティング VM（旧Notebook VM）では動作しない場合もありますが、ローカル ラップトップでは動作します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自動MLモデルを利用して予測ができました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 パイプラインの出力\r\n",
    "予測パイプラインは、各店舗のオレンジジュースの販売量をブランド別に予測します。パイプラインは、各店舗の予測を含む1つのファイルを返し、その結果をBLOBの forecasting_output コンテナに出力します。 BLOBコンテナーの詳細は、Outputs+logs の下の 'forecasting_output.txt' にリストされます。\r\n",
    "\r\n",
    "次のコードスニペットは：\r\n",
    "1. 並列実行ステップで渡された出力フォルダーの内容をダウンロードし\r\n",
    "2. 予測が含まれている parallel_run_step.txt ファイルを pandas データフレームとして読み取り\r\n",
    "3. 予測の上位10行を表示します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import shutil\r\n",
    "import os\r\n",
    "import sys \r\n",
    "from scripts.helper import get_forecasting_output\r\n",
    "\r\n",
    "forecasting_results_name = \"forecasting_results\"\r\n",
    "forecasting_output_name = \"many_models_inference_output\"\r\n",
    "\r\n",
    "forecast_file = get_forecasting_output(run, forecasting_results_name, forecasting_output_name)\r\n",
    "df = pd.read_csv(forecast_file, delimiter=\" \", header=None)\r\n",
    "df.columns = [\"Week Starting\", \"Store\", \"Brand\", \"Quantity\",  \"Advert\", \"Price\" , \"Revenue\", \"Predicted\" ]\r\n",
    "print(\"Prediction has \", df.shape[0], \" rows. Here the first 10 rows are being displayed.\")\r\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0 パイプラインの発行とスケジュール (オプション)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 パイプラインを発行する\r\n",
    "\r\n",
    "満足できるパイプラインを作成したら、パイプラインを発行して、後からプログラムで呼び出すことができます。パイプラインの発行と呼び出しの詳細については、この[チュートリアル](https://docs.microsoft.com/ja-jp/azure/machine-learning/how-to-create-machine-learning-pipelines#publish-a-pipeline)を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# published_pipeline = pipeline.publish(name = 'automl_forecast_many_models',\n",
    "#                                      description = 'forecast many models',\n",
    "#                                      version = '1',\n",
    "#                                      continue_on_step_failure = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 パイプラインのスケジュール実行\r\n",
    "また、時間ベースまたは変更ベースのスケジュールで実行するように[パイプラインをスケジュール](https://docs.microsoft.com/ja-jp/azure/machine-learning/how-to-trigger-published-pipeline)することもできます。これは、毎月、またはデータドリフトなどの別のトリガーに基づいて、モデルを自動的に再トレーニングまたは推論するために使用できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azureml.pipeline.core import Schedule, ScheduleRecurrence\n",
    "    \n",
    "# forecasting_pipeline_id = published_pipeline.id\n",
    "\n",
    "# recurrence = ScheduleRecurrence(frequency=\"Month\", interval=1, start_time=\"2020-01-01T09:00:00\")\n",
    "# recurring_schedule = Schedule.create(ws, name=\"automl_forecasting_recurring_schedule\", \n",
    "#                             description=\"Schedule Forecasting Pipeline to run on the first day of every week\",\n",
    "#                             pipeline_id=forecasting_pipeline_id, \n",
    "#                             experiment_name=experiment.name, \n",
    "#                             recurrence=recurrence)"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "deeptim"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('vscpy39': conda)",
   "name": "python391jvsc74a57bd03f5a1eed9b4ace55e909398ac91c318c6556c0b2dba69b98588c80e77c44e826"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}