{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# トレーニング パイプライン - カスタム スクリプト\r\n",
    "_**カスタム スクリプトを使用した Many models のトレーニング**_\r\n",
    "\r\n",
    "----\r\n",
    "\r\n",
    "このノートブックでは、カスタム スクリプトを使用して Many Models をトレーニングして登録するパイプラインを作成する方法を示します。[ParallelRunStep](https://docs.microsoft.com/ja-jp/azure/machine-learning/tutorial-pipeline-batch-scoring-classification) を利用して、モデルのトレーニング プロセスを並列化し、プロセスをより効率的にします。このソリューション アクセラレータでは、[OJ 販売データセット](https://azure.microsoft.com/ja-jp/services/open-datasets/catalog/sample-oj-sales-simulated/)を使用して、各店舗の売上とオレンジ ジュースのブランドを予測する個々のモデルをトレーニングします。\r\n",
    "\r\n",
    "ここで使用するモデルは、scikit-learn と pandas ユーティリティに基づいて構築された単純な回帰ベースの予測です。予測がどのように構築されているかを確認するには、トレーニング スクリプトを参照してください。この予測はデモ用に意図されているので、時系列モデリングで遭遇するさまざまな特殊なケースは扱いません。たとえばここでのモデルではすべての時系列が、欠損値のない連続した間隔で定期的にサンプリングされた観測値で構成されていることを前提としています。このモデルでは、カテゴリ変数の処理は含まれません。欠損値、高度な特徴付け、および自動的なモデル選択を処理する、より一般的な予測機能については、[AutoML 予測タスク](https://docs.microsoft.com/ja-jp/azure/machine-learning/how-to-auto-train-forecast)を参照してください。また、[Many Models シナリオにおける AutoML 予測](../Automated_ML)を示すノートブックを参照してください。\r\n",
    "\r\n",
    "### 前提条件\r\n",
    "この時点で、次の内容が完了している必要があります：\r\n",
    "\r\n",
    "1. [00_Setup_AML_Workspace notebook](../../00_Setup_AML_Workspace.ipynb) を使用して、AML ワークスペースが作成されていること\r\n",
    "2. [01_Data_Preparation.ipynb](../../01_Data_Preparation.ipynb) を実行してデータセットを作成していること"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Azure ML SDK の最新バージョンを使用していることを確認し、パイプライン ステップ パッケージをインストールしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade azureml-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install azureml-pipeline-steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 ワークスペースとデータストアへの接続"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\r\n",
    "\r\n",
    "# ワークスペースのセットアップ\r\n",
    "ws = Workspace.from_config()\r\n",
    "\r\n",
    "# データストアのセットアップ\r\n",
    "dstore = ws.get_default_datastore()\r\n",
    "\r\n",
    "print('Workspace Name: ' + ws.name, \r\n",
    "      'Azure Region: ' + ws.location, \r\n",
    "      'Subscription Id: ' + ws.subscription_id, \r\n",
    "      'Resource Group: ' + ws.resource_group, \r\n",
    "      sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 実験の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment = Experiment(ws, 'oj_training_pipeline')\n",
    "\n",
    "print('Experiment name: ' + experiment.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 トレーニング データセットの取得\r\n",
    "\r\n",
    "次に、[Dataset.get_by_name()](https://docs.microsoft.com/python/api/azureml-core/azureml.core.dataset.dataset#get-by-name-workspace--name--version--latest--) メソッドを使用してトレーニング データセットを取得します。\r\n",
    "\r\n",
    "これは[データ準備ノートブック](../01_Data_Preparation.ipynb)で作成および登録したトレーニング データセットです。ファイルのサブセットのみを使用するように選択した場合は、トレーニング データセット名を `oj_data_small_train` と指定します。それ以外の場合は、`oj_data_train` を指定します。\r\n",
    "\r\n",
    "小さなデータセットから始め、すべてが正常に実行された後に、完全なデータセットにスケールアップすることをお勧めします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'oj_data_small_train'\r\n",
    "#dataset_name = 'oj_data_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "dataset = Dataset.get_by_name(ws, name=dataset_name)\n",
    "dataset_input = dataset.as_named_input(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 トレーニング パイプラインの作成\r\n",
    "データセット、ワークスペースおよびデータストアが設定できたので、トレーニング用のパイプラインにまとめることができます。\r\n",
    "\r\n",
    "### 4.1 ParallelRunStep の環境を構成する\r\n",
    "[環境](https://docs.microsoft.com/ja-jp/azure/machine-learning/concept-environments)は、パイプラインを実行するために必要なリソースのコレクションを定義します。私たちは、[scikit-learn](https://scikit-learn.org/stable/index.html) Pythonライブラリを含むトレーニングスクリプト用の再現可能なPython環境を構成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "train_env = Environment(name=\"many_models_environment\")\n",
    "train_conda_deps = CondaDependencies.create(pip_packages=['sklearn', 'pandas', 'joblib', 'azureml-defaults', 'azureml-core', 'azureml-dataprep[fuse]'])\n",
    "train_env.python.conda_dependencies = train_conda_deps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 コンピュート ターゲットの選択"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在 PipelineRunBuilder は AMLCompute のみをサポートしています。これは[セットアップ ノートブック](../00_Setup_AML_Workspace.ipynb#3.0-Create-compute-cluster)で作成したコンピュート クラスタです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_cluster_name = \"cpucluster\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "\n",
    "compute = AmlCompute(ws, cpu_cluster_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 ParallelRunConfig の設定\r\n",
    "\r\n",
    "[ParallelRunConfig](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.parallel_run_config.parallelrunconfig?view=azure-ml-py) は、次で作成する ParallelRunStep の構成を提供します。ここでは、上記で作成した環境とコンピュート ターゲットと、各バッチ用のエントリ スクリプトを指定します。\r\n",
    "\r\n",
    "構成する重要なパラメーターには、以下の項目があります：\r\n",
    "- **mini_batch_size**: バッチあたりのファイル数。500 個のファイルがあり、mini_batch_sizeが 10 の場合、それぞれ 10 個のファイルを含む 50 個のバッチが作成されます。バッチは、さまざまなノードに分割されます。\r\n",
    "\r\n",
    "- **node_count**: ユーザー スクリプトの実行に使用するコンピューティング ノードの数。OJ データセットの小さなサンプルでは、1 つのノードのみが必要ですが、より多くのファイルで構成される大きなデータセットでは、この数を増やす必要があります。ここでノード数を 5 を超える場合は、コンピュート クラスターのmax_nodesも増やす必要があります。\r\n",
    "\r\n",
    "- **process_count_per_node**: ノードあたりのプロセス数。使用予定のコンピュート クラスターには 8 つのコアがあるため、このパラメーターを 8 に設定します。\r\n",
    "\r\n",
    "- **run_invocation_timeout**: run() メソッドの呼び出しタイムアウト (秒単位)。タイムアウトは、1 つのモデルの最大トレーニング時間 (秒単位) より大きく設定する必要があります。デフォルトは 60 秒です。トレーニングに最も時間がかかるバッチは約 120 秒であるため、メソッドの実行に十分な時間を確保するために 180 に設定します。\r\n",
    "\r\n",
    "\r\n",
    "また、トレーニング クラスターのノード数、ノードあたりのプロセス数、データセット名に関する情報を保持するタグも追加します。'Tags' 列は、Azure Machine Learning Studio で確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.steps import ParallelRunConfig\n",
    "\n",
    "processes_per_node = 8\n",
    "node_count = 1\n",
    "timeout = 180\n",
    "\n",
    "parallel_run_config = ParallelRunConfig(\n",
    "    source_directory='./scripts',\n",
    "    entry_script='train.py',\n",
    "    mini_batch_size=\"1\",\n",
    "    run_invocation_timeout=timeout,\n",
    "    error_threshold=10,\n",
    "    output_action=\"append_row\",\n",
    "    environment=train_env,\n",
    "    process_count_per_node=processes_per_node,\n",
    "    compute_target=compute,\n",
    "    node_count=node_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 ParallelRunStep の構成\r\n",
    "\r\n",
    "この [ParallelRunStep](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.parallel_run_step.parallelrunstep?view=azure-ml-py) はトレーニング パイプラインにおけるメインのステップです。\r\n",
    "\r\n",
    "まず出力ディレクトリを設定し、パイプラインの出力名を定義します。パイプラインの出力データを格納するデータストアは、ワークスペースのデフォルトデータストアです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineData\n",
    "\n",
    "output_dir = PipelineData(name=\"training_output\", datastore=dstore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは、ParallelRunConfig に対して名前と、上記で作成された他のいくつかのパラメータを与えます。\r\n",
    "\r\n",
    "- **inputs**: 入力データセットのリスト。ここでは、前のノートブックで作成したデータセットを使用します。そのパス内のファイル数によって、ParallelRunStep でトレーニングされるモデルの数が決まります。\r\n",
    "\r\n",
    "- **output**: 出力ディレクトリに対応する PipelineData オブジェクト。定義した出力ディレクトリを使用します。\r\n",
    "\r\n",
    "- **arguments**: train.py 入力スクリプトに必要な引数のリスト。ここでは、時系列データのスキーマ(例：ターゲット、タイムスタンプ、id列名)、モデリング前に削除する必要がある列、モデルの種類を識別する文字列、そしてテスト用に残しておきたい観測値の数を与えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.pipeline.steps import ParallelRunStep\n",
    "\n",
    "parallel_run_step = ParallelRunStep(\n",
    "    name=\"many-models-training\",\n",
    "    parallel_run_config=parallel_run_config,\n",
    "    inputs=[dataset_input],\n",
    "    output=output_dir,\n",
    "    allow_reuse=False,\n",
    "    arguments=['--target_column', 'Quantity', \n",
    "               '--timestamp_column', 'WeekStarting', \n",
    "               '--timeseries_id_columns', 'Store', 'Brand',\n",
    "               '--drop_columns', 'Revenue', 'Store', 'Brand',\n",
    "               '--model_type', 'lr',\n",
    "               '--test_size', 20]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 パイプラインの実行\r\n",
    "次に、実行するパイプラインを送信します。この実行では、トレーニング セットを使用して各データセットのモデルをトレーニングし、テスト セットを使用して適合度の精度メトリックを計算し、最終的にすべてのデータを使用してモデルを再トレーニングします。10 ファイルの場合、これには数分しかかかりませんが、完全なデータセットでは 1 時間以上かかる場合があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=[parallel_run_step])\n",
    "run = experiment.submit(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実行が完了するまで待機\r\n",
    "run.wait_for_completion(show_output=False, raise_on_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0 トレーニング パイプラインの結果を表示する\r\n",
    "train.py の実行メソッドで返されるデータフレームは、*parallel_run_step.txt* に出力されます。トレーニング パイプラインの結果を確認するには、そのファイルをダウンロードし、DataFrame にデータを読み取り、サンプル内のメトリックを含む結果を視覚化します。Azure Machine Learning トレーニング用コンピュート クラスターに送信された実行には、しばらく時間がかかることがあります。出力は、実行が完了するまで生成されません。Azure ポータル https://ml.azure.com で実行の状態を監視できます。\r\n",
    "\r\n",
    "### 6.1 ローカルに parallel_run_step.txt をダウンロードする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def download_results(run, target_dir=None, step_name='many-models-training', output_name='training_output'):\n",
    "    stitch_run = run.find_step_run(step_name)[0]\n",
    "    port_data = stitch_run.get_output_data(output_name)\n",
    "    port_data.download(target_dir, show_progress=True)\n",
    "    return os.path.join(target_dir, 'azureml', stitch_run.id, output_name)\n",
    "\n",
    "file_path = download_results(run, 'output')\n",
    "file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 ファイルを dataframe に変換する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(file_path + '/parallel_run_step.txt', sep=\" \", header=None)\n",
    "df.columns = ['Store', 'Brand', 'Model', 'File Name', 'ModelName', 'StartTime', 'EndTime', 'Duration',\n",
    "              'MSE', 'RMSE', 'MAE', 'MAPE', 'Index', 'Number of Models', 'Status']\n",
    "\n",
    "df['StartTime'] = pd.to_datetime(df['StartTime'])\n",
    "df['EndTime'] = pd.to_datetime(df['EndTime'])\n",
    "df['Duration'] = df['EndTime'] - df['StartTime']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 結果を確認する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = df['EndTime'].max()  - df['StartTime'].min()\n",
    "\n",
    "print('Number of Models: ' + str(len(df)))\n",
    "print('Total Duration: ' + str(total)[6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average MAPE: ' + str(round(df['MAPE'].mean(), 5)))\n",
    "print('Average MSE: ' + str(round(df['MSE'].mean(), 5)))\n",
    "print('Average RMSE: ' + str(round(df['RMSE'].mean(), 5)))\n",
    "print('Average MAE: '+ str(round(df['MAE'].mean(), 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Maximum Duration: '+ str(df['Duration'].max())[7:])\n",
    "print('Minimum Duration: ' + str(df['Duration'].min())[7:])\n",
    "print('Average Duration: ' + str(df['Duration'].mean())[7:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 モデル間でのパフォーマンスの視覚化\r\n",
    "\r\n",
    "ここでは、テスト用にサブセットを使用して実行中に計算されたエラーメトリックからいくつかのチャートを生成します。\r\n",
    "\r\n",
    "まず、すべてのモデルにおける平均絶対パーセンテージ誤差(MAPE)の分布を調べます："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = sns.boxplot(y='MAPE', data=df)\n",
    "fig.set_title('MAPE across all models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、ブランドまたは店舗によってそれを分解して、モデル全体のエラーの変動を確認します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = sns.boxplot(x='Brand', y='MAPE', data=df)\n",
    "fig.set_title('MAPE by Brand')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、異なるブランドのモデルがトレーニングにかかった時間を見ることもできます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "brand = df.groupby('Brand')\n",
    "brand = brand['Duration'].sum()\n",
    "brand = pd.DataFrame(brand)\n",
    "brand['time_in_seconds'] = [time.total_seconds()  for time in brand['Duration']]\n",
    "\n",
    "brand.drop(columns=['Duration']).plot(kind='bar')\n",
    "plt.xlabel('Brand')\n",
    "plt.ylabel('Seconds')\n",
    "plt.title('Total Training Time by Brand')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.0 パイプラインの発行とスケジュール (オプション)\r\n",
    "\r\n",
    "\r\n",
    "### 7.1 パイプラインを発行する\r\n",
    "満足できるパイプラインを作成したら、パイプラインを発行して、後からプログラムで呼び出すことができます。パイプラインの発行と呼び出しの詳細については、この[チュートリアル](https://docs.microsoft.com/ja-jp/azure/machine-learning/how-to-create-machine-learning-pipelines#publish-a-pipeline)を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# published_pipeline = pipeline.publish(name = 'train_many_models',\n",
    "#                                      description = 'train many models',\n",
    "#                                      version = '1',\n",
    "#                                      continue_on_step_failure = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 パイプラインのスケジュール実行\r\n",
    "また、時間ベースまたは変更ベースのスケジュールで実行するように[パイプラインをスケジュール](https://docs.microsoft.com/ja-jp/azure/machine-learning/how-to-trigger-published-pipeline)することもできます。これは、毎月、またはデータドリフトなどの別のトリガーに基づいて、モデルを自動的に再トレーニングするために使用できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azureml.pipeline.core import Schedule, ScheduleRecurrence\n",
    "    \n",
    "# training_pipeline_id = published_pipeline.id\n",
    "\n",
    "# recurrence = ScheduleRecurrence(frequency=\"Month\", interval=1, start_time=\"2020-01-01T09:00:00\")\n",
    "# recurring_schedule = Schedule.create(ws, name=\"training_pipeline_recurring_schedule\", \n",
    "#                             description=\"Schedule Training Pipeline to run on the first day of every month\",\n",
    "#                             pipeline_id=training_pipeline_id, \n",
    "#                             experiment_name=experiment.name, \n",
    "#                             recurrence=recurrence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 次のステップ\r\n",
    "モデルのトレーニングとスコア付けが終了したら、[03_CustomScript_Forecasting_Pipeline.ipynb](03_CustomScript_Forecasting_Pipeline.ipynb) に進み、作成したモデルを使用して予測を行います。"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "roastala"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('vscpy39': conda)",
   "name": "python391jvsc74a57bd03f5a1eed9b4ace55e909398ac91c318c6556c0b2dba69b98588c80e77c44e826"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}